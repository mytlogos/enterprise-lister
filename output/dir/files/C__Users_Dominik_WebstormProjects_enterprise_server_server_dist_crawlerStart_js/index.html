<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>Plato - C:/Users/Dominik/WebstormProjects/enterprise-server/server/dist/crawlerStart.js</title>

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="">
  <meta name="author" content="">

  <!--[if lt IE 9]>
  <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
  <![endif]-->

  <link href="../../assets/css/vendor/morris.css" rel="stylesheet">
  <link href="../../assets/css/vendor/bootstrap.css" rel="stylesheet">
  <link href="../../assets/css/vendor/font-awesome.css" rel="stylesheet">
  <link href="../../assets/css/vendor/codemirror.css" rel="stylesheet">
  <link href="../../assets/css/plato.css" rel="stylesheet">
  <link href="../../assets/css/plato-file.css" rel="stylesheet">

</head>

<body>

<div class="navbar navbar-fixed-top">
  <div class="container">
    <a class="navbar-brand" href="http://github.com/es-analysis/plato">Plato on Github</a>
    <ul class="nav navbar-nav">
      <li>
        <a href="../../index.html">Report Home</a>
      </li>
    </ul>
  </div>
</div>

<div class="jumbotron">
  <div class="container">
    <h1>C:/Users/Dominik/WebstormProjects/enterprise-server/server/dist/crawlerStart.js</h1>
  </div>
</div>

<div class="container aggregate-stats">
  <div class="row">
    <div class="col-md-6">
      <h2 class="header">Maintainability <a href="http://blogs.msdn.com/b/codeanalysis/archive/2007/11/20/maintainability-index-range-and-meaning.aspx"><i class="icon icon-info-sign" rel="popover" data-placement="top" data-trigger="hover" data-content="A value between 0 and 100 that represents the relative ease of maintaining the code. A high value means better maintainability." data-original-title="Maintainability Index"  data-container="body"></i></a></h2>
      <p class="stat">75.30</p>
    </div>
    <div class="col-md-6">
      <h2 class="header">Lines of code <i class="icon icon-info-sign" rel="popover" data-placement="top" data-trigger="hover" data-content="Source Lines of Code / Logical Lines of Code" data-original-title="SLOC/LSLOC" data-container="body"></i></h2>
      <p class="stat">365</p>
    </div>
  </div>
  <div class="row historical">
    <div class="col-md-6">
      <p id="chart_historical_maint" class="chart"></p>
    </div>
    <div class="col-md-6">
      <p id="chart_historical_sloc" class="chart"></p>
    </div>
  </div>
  <div class="row">
    <div class="col-md-6">
      <h2 class="header">Difficulty  <a href="http://en.wikipedia.org/wiki/Halstead_complexity_measures"><i class="icon icon-info-sign" rel="popover" data-placement="top" data-trigger="hover" data-content="The difficulty measure is related to the difficulty of the program to write or understand." data-original-title="Difficulty" data-container="body"></i></a></h2>
      <p class="stat">59.84</p>
    </div>
    <div class="col-md-6">
      <h2 class="header">Estimated Errors  <a href="http://en.wikipedia.org/wiki/Halstead_complexity_measures"><i class="icon icon-info-sign" rel="popover" data-placement="top" data-trigger="hover" data-content="Halstead's delivered bugs is an estimate for the number of errors in the implementation." data-original-title="Delivered Bugs" data-container="body"></i></a></h2>
      <p class="stat">3.24</p>
    </div>
  </div>
</div>

<div class="container charts">
  <div class="row">
    <h2 class="header">Function weight</h2>
  </div>
  <div class="row">
    <div class="col-md-6">
      <h3 class="chart-header">By Complexity <a href="http://en.wikipedia.org/wiki/Cyclomatic_complexity"><i class="icon icon-info-sign" rel="popover" data-placement="top" data-trigger="hover" data-content="This metric counts the number of distinct paths through a block of code. Lower values are better." data-original-title="Cyclomatic Complexity" data-container="body"></i></a></h3>
      <div id="fn-by-complexity" class="stat"></div>
    </div>
    <div class="col-md-6">
      <h3 class="chart-header">By SLOC  <i class="icon icon-info-sign" rel="popover" data-placement="top" data-trigger="hover" data-content="Source Lines of Code / Logical Lines of Code" data-original-title="SLOC/LSLOC" data-container="body"></i></h3>
      <div id="fn-by-sloc" class="stat"></div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <textarea id="file-source" class="col-md-12">&quot;use strict&quot;;
Object.defineProperty(exports, &quot;__esModule&quot;, { value: true });
const tslib_1 = require(&quot;tslib&quot;);
const scraper = tslib_1.__importStar(require(&quot;./externals/scraper&quot;));
const database_1 = require(&quot;./database&quot;);
const websocketManager_1 = require(&quot;./websocketManager&quot;);
const tools_1 = require(&quot;./tools&quot;);
// todo look into database trigger or maybe replace it with database listener, which notify user on changes?
// todo fill out all of the event listener
/**
 *
 */
async function notifyUser(rawNews) {
    tools_1.multiSingle(rawNews, (item) =&gt; delete item.id);
    let news = await database_1.Storage.addNews(rawNews);
    if (Array.isArray(news)) {
        news = news.filter((value) =&gt; value);
    }
    if (!news || (Array.isArray(news) &amp;&amp; !news.length)) {
        return;
    }
    // set news to medium
    await database_1.Storage.linkNewsToMedium();
    // broadcast news to online user
    // @ts-ignore
    websocketManager_1.broadCastNews(news);
}
function extractNewsMeta() {
    const likelyChapReg = /(\W|^)((ch(apter|(\.?\s?\d+)))|c\d+|episode|((extra|intermission|side.story).+))([^a-z]|$)/i;
    const probableChapReg = /(\W|^)part([^a-z]|$)/i;
    const likelyChapRegSensitive = /(\W|^)SS([^a-z]|$)/;
    const likelyVolReg = /(\W|^)(Vol(ume|\.)|v\d+|Arc|book)([^a-z]|$)/i;
    const volChapReg = /(\d+)-(\d+)/;
    const numberReg = /\d+/;
    /*if (chapter) {
        // if the chapter match is not at the beginning, sth else (novel title likely) is preceding it
        const chapStart = chapter.chapter.index;

        if (chapStart) {
            let novel = chapter.text.substring(0, chapStart).trim();

            if (chapter.volume) {
                const volStart = chapter.volume.index;
                result.volume = chapter.text.substring(volStart, chapStart);

                const volIndex = result.volume.match(/\d+/);
                result.volIndex = volIndex &amp;&amp; volIndex[0];

                if (volStart) {
                    novel = chapter.text.substring(0, volStart).trim();
                } else {
                    novel = &quot;&quot;;
                }
            }
            result.novel = novel;
        }

        result.chapter = chapter.text.substring(chapStart);

        const chapIndex = result.chapter.match(/\d+([,.]\d+)?/);
        result.chapIndex = chapIndex &amp;&amp; chapIndex[0];
    }
    let volume;

    if (!result.volume) {
        volume = volumes[0];

        if (volume &amp;&amp; !volume.chapter) {
            const volStart = volume.volume.index;
            result.volume = volume.text.substring(volStart);

            const volIndex = result.volume.match(/\d+([,.]\d+)?/);
            result.volIndex = volIndex &amp;&amp; volIndex[0];

            if (volStart) {
                result.novel = volume.text.substring(0, volStart).trim();
            }
        }
    }*/
}
/**
 *
 * @param result
 * @return {Promise&lt;void&gt;}
 */
async function feedHandler(result) {
    try {
        await notifyUser(result);
    }
    catch (e) {
        console.log(e);
    }
}
async function tocHandler(result) {
    console.log(&quot;toc: &quot;, result);
}
async function addFeeds(feeds) {
    if (!feeds.length) {
        return;
    }
    let scrapes = await database_1.Storage.getScrapes();
    scrapes = scrapes.filter((value) =&gt; value.type === scraper.scrapeTypes.FEED);
    const scrapeFeeds = feeds.map((feed) =&gt; {
        if (scrapes.find((value) =&gt; value.link === feed)) {
            return;
        }
        return {
            link: feed,
            type: scraper.scrapeTypes.FEED,
        };
    }).filter((value) =&gt; value);
    if (!scrapeFeeds.length) {
        return;
    }
    // @ts-ignore
    await database_1.Storage.addScrape(scrapeFeeds);
}
/**
 *
 */
async function processMedia(media, listType, userUuid) {
    // todo update the progress of each user
    const likeMedia = media.map((value) =&gt; {
        return {
            title: value.title.text,
            link: value.title.link,
        };
    });
    const currentLikeMedia = await database_1.Storage.getLikeMedium(likeMedia);
    const foundLikeMedia = [];
    // filter out the media which were found in the storage, leaving only the new ones
    const newMedia = media.filter((value) =&gt; {
        const likeMedium = Array.isArray(currentLikeMedia)
            ? currentLikeMedia.find((likedMedium) =&gt; {
                return likedMedium.title === value.title.text
                    &amp;&amp; likedMedium.link === value.title.link;
            })
            : currentLikeMedia;
        if (likeMedium) {
            foundLikeMedia.push(likeMedium);
            return false;
        }
        return true;
    });
    // if there are new media, queue it for scraping,
    // after adding it to the storage and pushing it to foundLikeMedia
    if (newMedia.length) {
        const storedMedia = await Promise.all(newMedia.map((scrapeMedium) =&gt; {
            // noinspection JSCheckFunctionSignatures
            return database_1.Storage
                .addMedium({ title: scrapeMedium.title.text, medium: scrapeMedium.medium })
                .then((value) =&gt; {
                return {
                    medium: value,
                    title: scrapeMedium.title.text,
                    link: scrapeMedium.title.link,
                };
            });
        }));
        foundLikeMedia.push(...storedMedia);
        // queue newly added media for scraping
        scraper.add({
            medium: storedMedia.map((value) =&gt; {
                return {
                    id: value.medium.id,
                    listType,
                };
            }),
        });
    }
    return foundLikeMedia;
}
/**
 *
 */
async function listHandler(result) {
    const feeds = result.lists.feed;
    const lists = result.lists.lists;
    const media = result.lists.media;
    // list of media, which are referenced in the scraped lists
    const likeMedia = await processMedia(media, result.external.type, result.external.userUuid);
    // add feeds to the storage and add them to the scraper
    await addFeeds(feeds);
    const currentLists = await database_1.Storage.getExternalLists(result.external.uuid);
    // all available stored list, which lie on the same index as the scraped lists
    const allLists = [];
    // new lists, which should be added to the storage
    const addedLists = [];
    // all renamed lists
    const renamedLists = [];
    lists.forEach((scrapeList, index) =&gt; {
        // check whether there is some list with the same name
        let listIndex = currentLists.findIndex((list) =&gt; list.name === scrapeList.name);
        if (listIndex &lt; 0) {
            // check whether there is some list with the same link even if it is another name
            listIndex = currentLists.findIndex((list) =&gt; list.url === scrapeList.link);
            // list was renamed if link is the same
            if (listIndex &gt;= 0) {
                renamedLists.push(scrapeList);
            }
        }
        // if scraped list is neither link or title matched, treat is as a newly added list
        if (listIndex &lt; 0) {
            addedLists.push(scrapeList);
        }
        else {
            allLists[index] = currentLists[listIndex];
        }
        // map the scrapeMedia to their id in the storage
        // @ts-ignore
        scrapeList.media = scrapeList.media.map((scrapeMedium) =&gt; {
            const likeMedium = likeMedia.find((like) =&gt; {
                return like &amp;&amp; like.link === scrapeMedium.title.link;
            });
            if (!likeMedium) {
                throw Error(&quot;missing medium in storage for &quot; + scrapeMedium.title.link);
            }
            return likeMedium.medium.id;
        });
    });
    // lists that are not in the scraped lists =&gt; lists that were deleted
    const removedLists = currentLists.filter((value) =&gt; !allLists.includes(value)).map((value) =&gt; value.id);
    const message = {};
    const promisePool = [];
    if (removedLists.length) {
        database_1.Storage
            .removeExternalList(result.external.uuid, removedLists)
            .then(() =&gt; {
            if (!message.remove) {
                message.remove = {};
            }
            message.remove.externalList = removedLists;
        })
            .catch(console.log);
    }
    // add each new list to the storage
    promisePool.push(...addedLists.map((value) =&gt; database_1.Storage
        .addExternalList(result.external.uuid, {
        name: value.name,
        url: value.link,
        medium: value.medium,
        items: value.media,
    })
        .then((externalList) =&gt; {
        if (!message.add) {
            message.add = {};
        }
        if (!message.add.externalList) {
            message.add.externalList = [];
        }
        externalList.uuid = result.external.uuid;
        message.add.externalList.push(externalList);
    })
        .catch(console.log)));
    promisePool.push(...renamedLists.map((value, index) =&gt; {
        const id = allLists[index].id;
        return database_1.Storage
            .updateExternalList({
            id,
            name: value.name,
        })
            .then(() =&gt; {
            if (!message.update) {
                message.update = {};
            }
            if (!message.update.lists) {
                message.update.lists = [];
            }
            message.update.lists.push({ external: true, id, name: value.name });
        })
            .catch(console.log);
    }));
    // check whether media were removed or added to the list
    allLists.forEach((externalList, index) =&gt; {
        const scrapeList = lists[index];
        const removedMedia = [...externalList.items];
        // @ts-ignore
        const newMedia = scrapeList.media.filter((mediumId) =&gt; {
            const mediumIndex = removedMedia.indexOf(mediumId);
            if (mediumIndex &lt; 0) {
                return true;
            }
            removedMedia.splice(mediumIndex, 1);
            return false;
        });
        promisePool.push(...removedMedia.map((mediumId) =&gt; database_1.Storage
            .removeItemFromExternalList(externalList.id, mediumId)
            .then(() =&gt; {
            if (!message.remove) {
                message.remove = {};
            }
            if (!message.remove.items) {
                message.remove.items = [];
            }
            message.remove.items.push({ external: true, listId: externalList.id, mediumId });
        })
            .catch(console.log)));
        promisePool.push(...newMedia.map((mediumId) =&gt; database_1.Storage
            .addItemToExternalList(externalList.id, mediumId)
            .then(() =&gt; {
            if (!message.add) {
                message.add = {};
            }
            if (!message.add.items) {
                message.add.items = [];
            }
            message.add.items.push({ external: true, listId: externalList.id, mediumId });
        })
            .catch(console.log)));
    });
    // update externalUser with (new) cookies and a new lastScrape date (now)
    promisePool.push(database_1.Storage
        // @ts-ignore
        .updateExternalUser({
        uuid: result.external.uuid,
        cookies: result.external.cookies,
        lastScrape: new Date(),
    })
        .catch(console.log));
    await Promise.all(promisePool);
    websocketManager_1.sendMessage(result.external.userUuid, message);
}
/**
 *
 * @param result
 * @return {Promise&lt;void&gt;}
 */
async function newsHandler(result) {
    console.log(&quot;news: &quot;, result);
    try {
        await notifyUser(result);
    }
    catch (e) {
        console.log(e);
    }
}
scraper.on(&quot;feed:error&quot;, (errorValue) =&gt; {
    console.log(errorValue);
});
scraper.on(&quot;toc:error&quot;, (errorValue) =&gt; {
    console.log(errorValue);
});
scraper.on(&quot;list:error&quot;, (errorValue) =&gt; {
    console.log(errorValue);
});
scraper.on(&quot;news:error&quot;, (errorValue) =&gt; {
    console.log(errorValue);
});
scraper.on(&quot;news&quot;, (result) =&gt; newsHandler(result).catch(console.log));
scraper.on(&quot;toc&quot;, (result) =&gt; tocHandler(result).catch(console.log));
scraper.on(&quot;feed&quot;, (result) =&gt; feedHandler(result).catch(console.log));
scraper.on(&quot;list&quot;, (result) =&gt; listHandler(result).catch(console.log));
const listenerList = [];
exports.startCrawler = () =&gt; {
    scraper.setup().then(() =&gt; scraper.start()).catch(console.log);
};
/**
 *
 * @param {function} listener
 * @return {undefined}
 */
exports.addErrorListener = (listener) =&gt; {
    listenerList.push(listener);
};
//# sourceMappingURL=crawlerStart.js.map</textarea>
  </div>
</div>

<footer class="footer">
  <div class="container">
    <p>.</p>
  </div>
</footer>

<script type="text/html" id="complexity-popover-template">
  <div class="complexity-notice">
    Complexity : {{ cyclomatic }} <br>
    Length : {{ halstead.length }} <br>
    Difficulty : {{ halstead.difficulty.toFixed(2) }} <br>
    Est # bugs : {{ halstead.bugs.toFixed(2) }}<br>
  </div>
</script>

<script type="text/javascript" src="../../assets/scripts/bundles/core-bundle.js"></script>
<script type="text/javascript" src="../../assets/scripts/bundles/codemirror.js"></script>
<script type="text/javascript" src="../../assets/scripts/codemirror.markpopovertext.js"></script>
<script type="text/javascript" src="report.js"></script>
<script type="text/javascript" src="report.history.js"></script>
<script type="text/javascript" src="../../assets/scripts/plato-file.js"></script>
</body>
</html>
